\section{SemantiBench Dataset}
\label{sec:benchmark}

To evaluate robustness, we introduce SemantiBench, a dynamic evaluation suite with over 100,000 hierarchically stratified prompt-mask pairs.

\paragraph{Data Source.} 
We aggregated data from three public repositories: the Medical Segmentation Decathlon (MSD), KiTS23, and BraTS2024. These datasets provide high spatial resolution and diverse target structures (tumors, organs, vessels). We resampled all volumes to a standardized isotropic spacing of $1.0 \times 1.0 \times 1.0$ mm and normalized them to the $[0, 1]$ intensity range using modality-specific windowing (e.g., lung windows for CT, T2-weighted for MRI).

\paragraph{Stress-Test Pipeline.}
We implemented an automated pipeline to generate prompts at three complexity levels ($L_g$). Using a Large Language Model (GPT-4), we transformed static labels into clinical directives:
\begin{itemize}
    \item \textbf{Level 1 ($L_1$):} Canonical anatomical terms (e.g., "Kidney").
    \item \textbf{Level 2 ($L_2$):} Direct visual descriptors, including intensity, shape, and texture information.
    \item \textbf{Level 3 ($L_3$):} Exclusion criteria and complex spatial relationships (e.g., "Heterogeneous mass in the right kidney, excluding the cyst").
\end{itemize}

\paragraph{Quality Control.}
To prevent mismatched prompts, we used a secondary verification step. A separate model checked the generated $L_3$ prompts against the ground truth metadata. Prompts containing contradictions (like describing a fluid-filled cyst as a solid tumor) were regenerated.

\paragraph{Dataset Statistics.}
The SemantiBench-100K dataset contains 12,000 unique volumes and 108,000 prompt variations across 14 anatomical structures in CT and MRI. The dataset is balanced with a 1:1:1 ratio of $L_1$, $L_2$, and $L_3$ prompts.

\section{Experiments}
\label{sec:experiments}

\paragraph{Implementation Details.}
We implemented SemantiSeg in PyTorch and trained it on 4 NVIDIA A100 GPUs. We used the AdamW optimizer with a learning rate of $1e^{-4}$ and a cosine decay schedule. Images were resized to $352 \times 352$ for the DWT module. We applied data augmentation, including elastic deformations and grid distortion, using Albumentations.

\paragraph{Baselines.}
We compared our method against three foundation models:
(1) \textbf{BiomedParse}~\cite{zhao2024biomedparse}: A joint parsing model using a CLIP-based backbone.
(2) \textbf{SAM-Med2D}~\cite{cheng2024sammed2d}: An adapter-based finetuned version of the Segment Anything Model.
(3) \textbf{FMISeg}: A frequency-domain fusion baseline without the semantic gating module, used as an ablation.

\paragraph{Results on SemantiBench.}
Table 1 shows the quantitative results.
