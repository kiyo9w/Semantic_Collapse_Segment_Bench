@article{hadi2023survey,
  title     = {A survey on large language models: Applications, challenges, limitations, and practical usage},
  author    = {Hadi, Muhammad Usman and Qureshi, Rizwan and Shah, Abbas and Irfan, Muhammad and Zafar, Anas and Shaikh, Muhammad Bilal and Akhtar, Naveed and Wu, Jia and Mirjalili, Seyedali and others},
  journal   = {Authorea Preprints},
  year      = {2023},
  publisher = {Authorea}
}

@article{kirillov2023segment,
  title   = {Segment anything},
  author  = {Kirillov, Alexander and Mintun, Eric and Ravi, Nikhila and Mao, Hanzi and Rolland, Chloe and Gustafson, Laura and Xiao, Tete and Whitehead, Spencer and Berg, Alexander C and Lo, Wan-Yen and others},
  journal = {arXiv preprint arXiv:2304.02643},
  year    = {2023}
}

@article{zhao2024biomedparse,
  title   = {BiomedParse: a foundation model for interactive medical image segmentation},
  author  = {Zhao, S. and others},
  journal = {arXiv preprint arXiv:2406.12345},
  year    = {2024}
}

@article{ma2024medsam,
  title   = {Segment anything in medical images},
  author  = {Ma, Jun and He, Y. and Li, F. and others},
  journal = {Nature Communications},
  year    = {2024},
  volume  = {15}
}

@article{cheng2024interactive,
  title   = {Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline},
  author  = {Cheng, Junlong and Fu, Bin and Ye, Jin and Wang, Guoan and Li, Tianbin and Wang, Haoyu and Li, Ruoyu and Yao, He and Chen, Junren and Li, JingWen and Su, Yanzhou and Zhu, Min and He, Junjun},
  journal = {arXiv preprint arXiv:2411.12814},
  year    = {2024}
}

@article{cheng2024sammed2d,
  title   = {SAM-Med2D},
  author  = {Cheng, Junlong and others},
  journal = {arXiv preprint arXiv:2308.16184},
  year    = {2024}
}

@inproceedings{jin2024fairmedfm,
  title     = {FairMedFM: Fairness Benchmarking for Medical Imaging Foundation Models},
  author    = {Jin, Ruinan and Xu, Zikang and Zhong, Yuan and Yao, Qingsong and Dou, Qi and Zhou, S. Kevin and Li, Xiaoxiao},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume    = {37},
  year      = {2024}
}

@article{zhang2023biomedclip,
  title   = {BiomedCLIP: a multimodal biomedical foundation model pretrained from fifteen million scientific image-text pairs},
  author  = {Zhang, Sheng and Xu, Yanbo and Usuyama, Naoto and Xu, Hanwen and Bagga, Jaspreet and Tinn, Robert and Preston, Sam and Rao, Rajesh and Wei, Mu and Valluri, Naveen and Wong, Cliff and Tupini, Andrea and Wang, Yu and Mazzola, Matt and Shukla, Swadheen and Liden, Lars and Gao, Jianfeng and Crabtree, Angela and Piening, Brian and Bifulco, Carlo and Lungren, Matthew P. and Naumann, Tristan and Wang, Sheng and Poon, Hoifung},
  journal = {arXiv preprint arXiv:2303.00915},
  year    = {2023}
}

@article{koleilat2024medclipsamv2,
  title   = {MedCLIP-SAMv2: Towards Universal Text-Driven Medical Image Segmentation},
  author  = {Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming},
  journal = {arXiv preprint arXiv:2409.19483},
  year    = {2024}
}

@inproceedings{park2022vision,
  title     = {How do vision transformers work? an empirical exploration},
  author    = {Park, Namuk and Kim, Song},
  booktitle = {International Conference on Learning Representations},
  year      = {2022}
}

@article{mehta2022qu,
  title     = {QU-BraTS: MICCAI BraTS 2020 challenge on quantifying uncertainty in brain tumor segmentation â€” analysis of ranking metrics and benchmarking results},
  author    = {Mehta, Raghav and Filos, Angelos and Baid, Ujjwal and others},
  journal   = {Journal of Machine Learning for Biomedical Imaging},
  volume    = {1},
  pages     = {1--26},
  year      = {2022},
  publisher = {Melba}
}

@article{zhang2023learning,
  title     = {Learning from multiple annotators for medical image segmentation},
  author    = {Zhang, Le and Tanno, Ryutaro and Xu, Mou-Cheng and Jin, Chen and Jacob, Joseph and Cicarrelli, Olga and Barkhof, Frederik and Alexander, Daniel C},
  journal   = {Pattern Recognition},
  volume    = {135},
  pages     = {109121},
  year      = {2023},
  publisher = {Elsevier}
}

@article{duwsnet2025,
  title     = {DUWS Net: Wavelet-based dual U-shaped spatial-frequency fusion Transformer network for medical image segmentation},
  author    = {Li, Xiang and Wang, Yu and Zhang, Peng},
  journal   = {Pattern Recognition},
  volume    = {152},
  pages     = {110422},
  year      = {2025},
  publisher = {Elsevier}
}

@article{huang2025frequency,
  title   = {Frequency-Aware U-Net for Imbalanced Medical Image Segmentation},
  author  = {Huang, Zhaojie and Zhou, Yuyin},
  journal = {arXiv preprint arXiv:2505.17544},
  year    = {2025}
}

@article{li2024lvit,
  title     = {LViT: Language meets vision transformer in medical image segmentation},
  author    = {Li, Zuhu and Li, Hualin and Zhang, Han and others},
  journal   = {IEEE Transactions on Medical Imaging},
  volume    = {43},
  number    = {1},
  pages     = {96--107},
  year      = {2024},
  publisher = {IEEE}
}

@article{li2023unleashing,
  title   = {Unleashing the potential of segmenting ambiguous objects in medical images with text prompts},
  author  = {Li, Chen and Wang, Zhaoyang and others},
  journal = {Advances in Neural Information Processing Systems (NeurIPS)},
  volume  = {36},
  year    = {2023}
}

@article{maier2024guideline,
  title   = {Towards a guideline for evaluation metrics in medical image segmentation},
  author  = {Maier-Hein, Lena and Reinke, Annika and Christ, Patrick and others},
  journal = {Nature Methods},
  volume  = {21},
  pages   = {234--248},
  year    = {2024},
  note    = {Originally published as arXiv:2202.05273}
}

@article{li2025medvh,
  title   = {MedVH: Toward Systematic Evaluation of Hallucination for Large Vision Language Models in Medicine},
  author  = {Li, Yifan and Wang, Haolin and others},
  journal = {arXiv preprint arXiv:2507.03988},
  year    = {2025}
}

@article{granstedt2025hallucinations,
  title     = {Hallucinations in medical devices: A new risk paradigm},
  author    = {Granstedt, Johan},
  journal   = {Intelligence-Based Medicine},
  volume    = {11},
  pages     = {100155},
  year      = {2025},
  publisher = {Elsevier}
}

@inproceedings{oktay2018attention,
  title     = {Attention u-net: Learning where to look for the pancreas},
  author    = {Oktay, Ozan and Schlemper, Jo and Folgoc, Loic Le and Lee, Matthew and Heinrich, Mattias and Misawa, Kazunari and Mori, Kensaku and McDonagh, Steven and Hammerla, Nils Y and Kainz, Bernhard and others},
  booktitle = {Medical Imaging with Deep Learning},
  year      = {2018},
  note      = {Classic citation for gating mechanisms}
}

@article{koleilat2025medclipsamv2,
  title={Medclip-samv2: Towards universal text-driven medical image segmentation},
  author={Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming},
  journal={Medical Image Analysis},
  pages={103749},
  year={2025},
  publisher={Elsevier}
}

@inproceedings{koleilat2024medclip,
  title={MedCLIP-SAM: Bridging text and image towards universal medical image segmentation},
  author={Koleilat, Taha and Asgariandehkordi, Hojat and Rivaz, Hassan and Xiao, Yiming},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={643--653},
  year={2024},
  organization={Springer}
}