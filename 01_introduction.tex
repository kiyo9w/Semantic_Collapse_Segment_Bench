\section{Introduction}
\label{sec:intro}

The paradigm of "Segment Anything" has shifted the medical imaging landscape from specialized, task-specific networks to universal, promptable foundation models \cite{kirillov2023segment,zhao2024biomedparse}. Recent works such as BiomedParse \cite{zhao2024biomedparse} and MedSAM \cite{ma2024medsam} have demonstrated impressive capabilities in parsing diverse biomedical objects using natural language prompts, promising a future of zero-shot clinical applicability. However, a critical gap remains between this promise and clinical reality: \textbf{Semantic Robustness}.

Current evaluations are deceptively optimistic because they predominantly test on "Atomic" ($L_1$) queries---simple anatomical nouns like \textit{"liver"} or \textit{"lung"}. In contrast, real-world clinical directives are often "Complex" ($L_3$)---attribute-rich descriptions requiring compositional reasoning, such as \textit{"hypodense lesion in segment IV excluding the portal vein"}. We observe a phenomenon we term \textbf{Semantic Collapse}, where foundational models, overwhelmed by complex syntax, revert to segmenting the dominant anatomical structure rather than the specific pathological sub-region. As illustrated in Fig.~\ref{fig:teaser}, when prompted with \textit{"necrotic tumor core"}, state-of-the-art (SOTA) models often ignore the adjectival constraint ("necrotic") and segment the noun ("tumor"), resulting in clinically dangerous false positives.

\begin{figure}[t]
    \centering
    % ==========================================================================================
    % [VISUALIZATION SPECIFICATION: The "Problem vs. Solution" Teaser]
    % LOCATION: Top of Page 1 or 2 (Immediate visual hook)
    % GOAL: Visually define "Semantic Collapse" vs "SemantiSeg" (Solution)
    % ------------------------------------------------------------------------------------------
    % PANEL A: The "Semantic Collapse" Failure Mode (The Hook)
    % - Input Image: CT scan of a kidney tumor with a visible necrotic center (darker core).
    % - Prompt Displayed: "Necrotic Tumor Core" (highlight "Necrotic" in RED text).
    % - Baseline Model Output (BiomedParse): Show a segmentation mask that covers the ENTIRE tumor 
    %   (both the rim and the core).
    % - Visual Annotation: Draw a Red "X" over the mask or a label "Failed Constraint: Included Tumor Rim".
    % - Caption Concept: SOTA models ignore adjectives (complexity) and revert to nouns.
    %
    % PANEL B: The "SemantiBench" Stress Test (The Method)
    % - Visual: A hierarchical pyramid or flow diagram showing 3 prompt levels.
    %   * Level 1 (Base): "Tumor"
    %   * Level 2 (Descriptive): "Right Kidney Tumor"
    %   * Level 3 (Complex): "Necrotic Core"
    % - Action: Arrow pointing from L1 to L3 labeled "Increasing Semantic Complexity".
    %
    % PANEL C: Your Solution (SemantiSeg)
    % - Input Image: Same CT scan as Panel A.
    % - Prompt: "Necrotic Tumor Core" (highlight "Necrotic" in GREEN).
    % - Your Model Output: Show a mask that ONLY covers the dark center.
    % - Visual Annotation: Green Checkmark and a label: "Gated by Adjective".
    % ------------------------------------------------------------------------------------------
    % IMPLEMENTATION GUIDE:
    % 1. Data Layer: Use ITK-SNAP/3D Slicer. Manually edit segmentation to show "Bad" (full) vs "Good" (core).
    %    Take high-res screenshots (PNG) on BLACK background.
    % 2. Layout Layer: Use Draw.io or Inkscape. Import screenshots. Add monospace prompt text overlays.
    %    Use distinct colors (Red/Orange for Bad, Cyan/Green for Good). Use semi-transparent fills.
    % ==========================================================================================
    
    \fbox{\begin{minipage}[c][0.4\textwidth][c]{0.95\textwidth}
        \centering
        \ttfamily
        \Large [PLACEHOLDER: TEASER FIGURE]\\
        \normalsize
        See comments for detailed visualization architecture (Panels A, B, C)
    \end{minipage}}

    \caption{\textbf{Semantic Collapse vs. Semantic Gating.} (A) Existing foundation models (BiomedParse) fail to process the adjective "necrotic," incorrectly segmenting the entire tumor mass~\cite{zhao2024biomedparse}. (B) Our SemantiBench evaluates robustness across three linguistic levels ($L_1-L_3$). (C) SemantiSeg utilizes Cross-Modal Gating to correctly isolate the necrotic core.}
    \label{fig:teaser}
\end{figure}

To quantify and mitigate this failure mode, we present three primary contributions. First, we introduce \textbf{SemantiBench}, moving beyond static datasets to a dynamic evaluation protocol. We constructed a \textit{Semantic Stress-Test Pipeline} using agentic Large Language Models (LLMs) to generate hierarchically stratified prompts (Atomic $L_1$, Descriptive $L_2$, Complex $L_3$) for standard datasets, enabling the first systematic measurement of semantic fragility. Second, we propose the \textbf{Prompt Sensitivity Score (PSS)}, a new metric that quantifies the "robustness gap" between simple and complex queries. Our benchmarking reveals that current SOTA models suffer a high PSS (up to 0.29), indicating severe instability. Third, we propose \textbf{SemantiSeg}, a novel architecture utilizing \textit{Cross-Modal Semantic Gating (CMSG)} to dynamically filter spatial features based on textual attributes, reducing the PSS to $<0.05$.
