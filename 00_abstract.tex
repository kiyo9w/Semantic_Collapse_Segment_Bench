\begin{abstract}
While foundational models like BiomedParse and SAM have revolutionized biomedical segmentation through text-to-mask capabilities, they exhibit a critical failure mode we term \textbf{"Semantic Collapse"}---a significant performance degradation when moving from coarse anatomical targets (e.g., "kidney") to fine-grained pathological descriptions (e.g., "necrotic tumor core"). Current benchmarks, which rely on static class labels, fail to capture this fragility. In this work, we introduce \textbf{SemantiBench}, a hierarchical robustness benchmark comprising 100,000+ linguistically stratified prompt-mask pairs, generated via a novel Automated Semantic Stress-Test Pipeline. Leveraging this benchmark, we identify that SOTA models suffer a 29\% performance drop on complex clinical queries ($L_3$). To address this, we propose \textbf{SemantiSeg}, a novel architecture featuring \textit{Cross-Modal Semantic Gating (CMSG)} that explicitly decouples spatial localization from semantic attribute verification. Extensive experiments demonstrate that SemantiSeg maintains robust performance (Prompt Sensitivity Score $< 0.05$) where purely data-driven baselines fail.

\keywords{Medical Image Segmentation \and Foundation Models \and Semantic Robustness \and Benchmarking}
\end{abstract}
